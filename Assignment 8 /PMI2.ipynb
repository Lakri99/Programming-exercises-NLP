{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\awant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import glob, os, operator, re\n",
    "import string\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_text = []\n",
    "pos_text = []\n",
    "\n",
    "directory_list = ['neg', 'pos']\n",
    "for folder_name in directory_list:\n",
    "    read_files = glob.glob('./movie_review_data/'+folder_name+'/*.txt')\n",
    "    for f in read_files:\n",
    "        with open(f, \"r+\", encoding=\"utf-8\") as infile:\n",
    "            text = infile.read()\n",
    "            infile.close()\n",
    "            \n",
    "            if folder_name == 'neg':\n",
    "                neg_text.append(text)\n",
    "            elif folder_name == 'pos':\n",
    "                pos_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = re.compile(r'<[^>]+>').sub(' ', str(text))\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.translate(str.maketrans('', '', string.digits))\n",
    "    text = text.lower().split()\n",
    "    return text\n",
    "\n",
    "def find_unigrams(text):\n",
    "    return Counter(text)\n",
    "\n",
    "def find_bigrams(text):\n",
    "    return Counter(zip(text, islice(text, 1, None)))\n",
    "\n",
    "def process_ngrams(ngrams, mode):\n",
    "    keys = ngrams.keys()\n",
    "    pngrams = ngrams.copy()\n",
    "    \n",
    "    for key in list(keys):\n",
    "        for stopword in stop_words:\n",
    "            if mode == 'uni':\n",
    "                if stopword == key or ngrams[key] < 100:\n",
    "                    del pngrams[key]\n",
    "            elif mode == 'bi':\n",
    "                 if stopword in list(key) or ngrams[key] < 50:\n",
    "                    del pngrams[key]\n",
    "    return pngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = preprocess_text(neg_text)\n",
    "positive = preprocess_text(pos_text)\n",
    "\n",
    "neg_uni = find_unigrams(negative)\n",
    "neg_bi = find_bigrams(negative)\n",
    "\n",
    "pos_uni = find_unigrams(positive)\n",
    "pos_bi = find_bigrams(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneg_uni = process_ngrams(neg_uni,'uni')\n",
    "pneg_bi = process_ngrams(neg_bi,'bi')\n",
    "ppos_uni = process_ngrams(pos_uni,'uni')\n",
    "ppos_bi = process_ngrams(pos_bi,'bi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_vocab = list(set(pneg_uni + ppos_uni))\n",
    "bi_vocab = list(set(pneg_bi + ppos_bi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pmi(neg, pos, vocab):\n",
    "    neg_pmi = {}\n",
    "    pos_pmi = {}\n",
    "    \n",
    "    n = sum(neg.values()) #total tokens in negative text\n",
    "    p = sum(pos.values()) #total tokens in positive text\n",
    "    total = n+p\n",
    "    \n",
    "    P_neg = n/total #probability of negative class #not used for now\n",
    "    P_pos = p/total #probability of positive class #not used for now\n",
    "    \n",
    "    for word in vocab:\n",
    "        neg_count = pos_count = 0\n",
    "        if word in neg.keys():\n",
    "            neg_count = neg[word]\n",
    "        if word in pos.keys():\n",
    "            pos_count = pos[word]\n",
    "\n",
    "        P_neg_word = neg_count/total #P(word,neg)\n",
    "        P_pos_word = pos_count/total #P(word,pos)\n",
    "\n",
    "        P_word = (neg_count+pos_count)/total\n",
    "        try:\n",
    "            neg_pmi[word] = math.log(P_neg_word/(P_word * P_neg))\n",
    "        except:\n",
    "            neg_pmi[word] = 0\n",
    "        try:\n",
    "            pos_pmi[word] = math.log(P_pos_word/(P_word * P_pos))\n",
    "        except: \n",
    "            pos_pmi[word] = 0\n",
    "\n",
    "    return neg_pmi, pos_pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative unigram PMI\n",
      "{'boll': 0.6990501447864198, 'seagal': 0.6845875647331474, 'mstk': 0.6765879727521168, 'unwatchable': 0.6687934760151752, 'incoherent': 0.6540508408730659, 'unfunny': 0.6416110301570299, 'waste': 0.6384418026770593, 'blah': 0.6323602703848789, 'horrid': 0.6246552240104736, 'pointless': 0.6229866870450217, 'drivel': 0.6213711488092838, 'atrocious': 0.61940586812433, 'redeeming': 0.6168002787204079, 'prom': 0.614234491764741, 'lousy': 0.6134593156013486, 'worst': 0.6099491551514659, 'laughable': 0.605797205376077, 'awful': 0.6046985385299606, 'poorly': 0.6045921439729667, 'remotely': 0.6009447442380652}\n",
      "\n",
      "Positive unigram PMI\n",
      "{'edie': 0.6795874359385078, 'paulie': 0.6696371050853397, 'felix': 0.6411211551107117, 'matthau': 0.6263429214196956, 'victoria': 0.6157359639519752, 'flawless': 0.6123352089293405, 'mildred': 0.6119287874646929, 'astaire': 0.5942275869873511, 'superbly': 0.5859019518611848, 'perfection': 0.5798880757154198, 'wonderfully': 0.5629829508015687, 'captures': 0.5618044002821243, 'powell': 0.5468279460925672, 'bourne': 0.5444126575702553, 'refreshing': 0.5439632626408547, 'mustsee': 0.5437858947794459, 'gripping': 0.5391356004694114, 'elvira': 0.5377572404992903, 'delightful': 0.5333708837866695, 'lincoln': 0.5266180911570806}\n"
     ]
    }
   ],
   "source": [
    "neg_uni_pmi, pos_uni_pmi = find_pmi(neg_uni, pos_uni, uni_vocab)\n",
    "\n",
    "print(\"Negative unigram PMI\")\n",
    "print(dict(sorted(neg_uni_pmi.items(), key=lambda x: x[1], reverse=True)[:20]))\n",
    "print(\"\\nPositive unigram PMI\")\n",
    "print(dict(sorted(pos_uni_pmi.items(), key=lambda x: x[1], reverse=True)[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative bigram PMI\n",
      "{('prom', 'night'): 0.7068933270733797, ('even', 'worth'): 0.7068933270733797, ('terrible', 'movie'): 0.7068933270733797, ('worst', 'films'): 0.6978434915534619, ('uwe', 'boll'): 0.6944708070748229, ('total', 'waste'): 0.6897988937140799, ('worst', 'movies'): 0.6877539868626824, ('movie', 'sucks'): 0.6874752412162782, ('badly', 'written'): 0.6870906997772003, ('terrible', 'film'): 0.6870906997772003, ('bad', 'bad'): 0.6833628296631858, ('worst', 'film'): 0.6818293584101638, ('awful', 'movie'): 0.6765879775780509, ('worst', 'movie'): 0.6733706350347364, ('money', 'back'): 0.66661942793544, ('dont', 'waste'): 0.6665652816864079, ('complete', 'waste'): 0.664333712654584, ('power', 'rangers'): 0.6581031629039479, ('poor', 'acting'): 0.657296385934008, ('horrible', 'movie'): 0.6556000326858293}\n",
      "\n",
      "Positive bigram PMI\n",
      "{('red', 'sox'): 0.6795874312425673, ('gunga', 'din'): 0.6795874312425672, ('rob', 'roy'): 0.6676112401958515, ('midnight', 'cowboy'): 0.6633269103707867, ('nancy', 'drew'): 0.6630581292913565, ('wonderful', 'movie'): 0.6615689257398886, ('police', 'story'): 0.6601693453854656, ('excellent', 'movie'): 0.6488157725758134, ('perfectly', 'cast'): 0.6425461595622182, ('well', 'worth'): 0.6407056436983596, ('highly', 'recommended'): 0.6403667180892859, ('favorite', 'movies'): 0.6344669959620975, ('definitely', 'worth'): 0.6291565776156753, ('excellent', 'job'): 0.6180295382431337, ('michael', 'jackson'): 0.6043640100049796, ('wonderful', 'film'): 0.6043640100049796, ('walter', 'matthau'): 0.6026263901064388, ('first', 'rate'): 0.5940652578044052, ('dirty', 'harry'): 0.5831271650550048, ('best', 'movies'): 0.5689218633550475}\n"
     ]
    }
   ],
   "source": [
    "neg_bi_pmi, pos_bi_pmi = find_pmi(neg_bi, pos_bi, bi_vocab)\n",
    "\n",
    "print(\"Negative bigram PMI\")\n",
    "print(dict(sorted(neg_bi_pmi.items(), key=lambda x: x[1], reverse=True)[:20]))\n",
    "print(\"\\nPositive bigram PMI\")\n",
    "print(dict(sorted(pos_bi_pmi.items(), key=lambda x: x[1], reverse=True)[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMI of good and bad in Negative Class\n",
      "-0.003467875940748813\n",
      "0.4790195370818304\n",
      "\n",
      "PMI of good and bad in Positive Class\n",
      "0.0033629582298617816\n",
      "-0.9111501666679825\n"
     ]
    }
   ],
   "source": [
    "print(\"PMI of good and bad in Negative Class\")\n",
    "print(neg_uni_pmi['good'])\n",
    "print(neg_uni_pmi['bad'])\n",
    "\n",
    "print(\"\\nPMI of good and bad in Positive Class\")\n",
    "print(pos_uni_pmi['good'])\n",
    "print(pos_uni_pmi['bad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
