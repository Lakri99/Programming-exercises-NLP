{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"SNLPAssg7_2.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"gj32h1ZWzCj6","colab_type":"text"},"source":["Imports made"]},{"cell_type":"code","metadata":{"id":"46kb_ky7iGI1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593163268624,"user_tz":-120,"elapsed":1309,"user":{"displayName":"Awantee Deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQyP5l1inxcqIGxhx37HHAGXm1H1N-mYkv12YHVQ=s64","userId":"15044079699499406952"}},"outputId":"20200d33-43b6-4c2f-cbdf-9e6744af763c"},"source":["import nltk\n","nltk.download('treebank')\n","from nltk.corpus import treebank as ptb\n","\n","import numpy as np\n","import math\n","from collections import Counter\n","from itertools import islice"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Package treebank is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iCCttIZvzHYS","colab_type":"text"},"source":["###Necessary functions to implement for the Class Based Model"]},{"cell_type":"code","metadata":{"id":"hLlbrKdliGJN","colab_type":"code","colab":{}},"source":["#Find (word, word) Bigrams in the (Word,POS Tag) Tuples\n","def find_bigrams(text):\n","    bi_dict = {}\n","    for i in range(0, len(text) - 1):\n","        (first, second) = (text[i][0], text[i+1][0])\n","        if not (first, second) in bi_dict:\n","            bi_dict[(first, second)] = 1\n","        else:\n","            bi_dict[(first, second)] += 1\n","    return bi_dict    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h81xZiQDiGJ2","colab_type":"code","colab":{}},"source":["#Get word related parameters\n","def get_params_words(d, unigrams, vocab):\n","    \n","    #params to return\n","    N1_plus_wi1 = dict() \n","    N_bigrams = dict()\n","    lambda_wi = dict()\n","    P_abs_wi = dict()\n","    \n","    P_unif = 1/len(vocab)\n","    N_unis = sum(unigrams.values())\n","    N1_plus = len(unigrams) #eqn 11\n","    \n","    lambdadot_w = (d/N_unis) * N1_plus #eqn 10\n","    \n","    for word in vocab:\n","        P_abs_wi[word] = (max((unigrams[word] - d), 0)/N_unis) + (lambdadot_w * P_unif) #eqn 7\n","          \n","    return P_unif, lambdadot_w, P_abs_wi\n","\n","#Get POS Tag related parameters\n","def get_params_pos(d, pos_uni, pos_bi, pos_classes):\n","    \n","    N1_plus_pos_1 = dict()\n","    N_pos_bi = dict() \n","    lambda_pos_1 = dict()\n","    P_abs_pos = dict()\n","    \n","    Pos_unif = 1/len(pos_classes)\n","    N_pos_unis = sum(pos_uni.values()) \n","    N1_plus_pos = len(pos_uni) #eqn 17\n","    \n","    lambdadot_p = (d/N_pos_unis) * N1_plus_pos #eqn 16\n","    \n","    for pos in pos_classes:\n","        count = 0 #unique (pos,pos) starting with word\n","        N = 0 #total number of (pos,pos) starting with word\n","        \n","        for key, val in pos_bi.items():\n","            if(key[0] == pos):\n","                if(val > 0):\n","                    count += 1\n","                    N += val\n","        \n","        N1_plus_pos_1[pos] = count #eqn 15\n","        N_pos_bi[pos] = N #no. of (pos1, pos2) beginning with pos1\n","        \n","        if N > 0:\n","            lambdad = (d/N) * N1_plus_pos_1[pos] #eqn 14\n","        else:\n","            lambdad = 0\n","            \n","        lambda_pos_1[pos] = lambdad\n","        P_abs_pos[pos] = (max((pos_uni[pos] - d), 0)/N_pos_unis) + (lambdadot_p * Pos_unif) #eqn 13\n","    \n","    return Pos_unif, lambdadot_p, N_pos_bi, lambda_pos_1, P_abs_pos\n","\n","def get_P_abs_wi1_class(wi,wi_1,d,words,words_pos,pos_uni,pos_bi,lambda_pos,P_abs_pos,lambdadot_w, lambdadot_p,\n","                  word_pos_dict, Pos_unif,P_unif,pos_classes,P_abs_wi):\n","    \n","    \n","    pos_1 = word_pos_dict[wi_1]\n","    P_abs_w_wi = 0\n","    \n","    for pos in pos_classes:\n","        prob_w = 0\n","        prob_p = 0\n","        try:\n","            if(wi,pos) not in words_pos.keys():\n","                if pos not in lambda_pos.keys():\n","                    if wi not in words.keys():\n","                        prob_w = lambdadot_w * P_unif\n","                    else:\n","                        prob_w = P_abs_wi[wi]\n","                else:\n","                    prob_w = lambda_pos[pos] * P_abs_wi[wi]\n","            else:\n","                prob_w = (max((words_pos[(wi,pos)] - d), 0)/pos_uni[pos]) + (lambda_pos[pos] * P_abs_wi[wi])\n","        except:\n","            prob_w = lambdadot_w * P_unif\n","        \n","        try:\n","            if lambda_pos[pos_1] == 0:\n","                prob_p = lambdadot_pos * Pos_unif\n","            else:\n","                prob_p = (max((pos_bi[(pos_1,pos)] - d), 0)/pos_uni[pos_1]) + (lambda_pos[pos_1] * P_abs_pos[pos])\n","        except:\n","            prob_p =lambdadot_pos * Pos_unif\n","    \n","        P_abs_w_wi += prob_w * prob_p\n","    \n","    return P_abs_w_wi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RUg5wstF5-Sq","colab_type":"text"},"source":["###Necessary Functions to implement for Absolute Discounting Model"]},{"cell_type":"code","metadata":{"id":"Ue1jGmzl0kBm","colab_type":"code","colab":{}},"source":["def get_params_absdisc(d, bigrams, unigrams, vocab):\n","    \n","    #params to return\n","    N1_plus_wi1 = dict() #eqn 10\n","    N_bigrams = dict() #denominator of 7, 9\n","    lambda_wi = dict() #eqn 9\n","    P_abs_wi = dict() #eqn 8\n","    \n","    P_unif = 1/len(vocab)\n","    N_unis = sum(unigrams.values())\n","    N1_plus = len(unigrams)\n","    lambdadot = (d/N_unis) * N1_plus\n","    \n","    for word in vocab:\n","        count = 0 #unique bigrams starting with word\n","        N = 0 #total number of bigrams starting with word\n","        \n","        for key, val in bigrams.items():\n","            if(key[0] == word):\n","                if(val > 0):\n","                    count += 1\n","                    N += val\n","        \n","        N1_plus_wi1[word] = count \n","        N_bigrams[word] = N\n","        \n","        if N > 0:\n","            lambdad = (d/N) * N1_plus_wi1[word]\n","        else:\n","            lambdad = 0\n","            \n","        lambda_wi[word] = lambdad\n","        P_abs_wi[word] = (max((unigrams[word] - d), 0)/N_unis) + (lambdadot * P_unif)\n","          \n","    return P_unif, lambdadot, N1_plus_wi1, N_bigrams, lambda_wi, P_abs_wi\n","\n","\n","def get_P_abs_wi1_absdisc(wi, wi_1, d, unigrams, bigrams, N_bigrams, lambda_wi, P_abs_wi, lambdadot, P_unif):\n","    try:\n","        if((wi_1, wi) not in bigrams.keys()):\n","            if(wi_1 not in lambda_wi.keys()):\n","                if(wi not in P_abs_wi.keys()):\n","                    P_abs_wi1 = lambdadot * P_unif\n","                else:\n","                    P_abs_wi1 = P_abs_wi[wi]\n","            else:\n","                P_abs_wi1 = (lambda_wi[wi_1] * P_abs_wi[wi])\n","        else:\n","            N = N_bigrams[wi_1]\n","            P_abs_wi1 = (max((bigrams[(wi_1, wi)] - d), 0)/N) + (lambda_wi[wi_1] * P_abs_wi[wi])\n","    except:\n","        P_abs_wi1 = lambdadot * P_unif\n","    return P_abs_wi1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dn4Yfmzk6Fa4","colab_type":"text"},"source":["###Find conditional probabilities for Class Model and Absolute Discounting Model"]},{"cell_type":"code","metadata":{"id":"-uPj22uEiGKE","colab_type":"code","colab":{}},"source":["#Find conditional probabilites based on test set for the (Word,POS Tag) tuples\n","def find_cond_prob_class(d, words, words_pos, vocab, pos_uni, pos_bi, pos_classes, word_pos_dict, bi_test):\n","    \n","    cond_prob = dict()\n","    \n","    P_unif, lambdadot_w, P_abs_wi = get_params_words(d, words, vocab)\n","    Pos_unif, lambdadot_p, N_pos_bi, lambda_pos, P_abs_pos = get_params_pos(d, pos_uni, pos_bi, pos_classes)\n","    \n","    for k,v in bi_test.items():\n","        cond_prob[k] = get_P_abs_wi1_class(k[1], k[0],d,words,words_pos,pos_uni,pos_bi,lambda_pos,P_abs_pos,lambdadot_w,\n","                                    lambdadot_p,word_pos_dict,Pos_unif,P_unif,pos_classes,P_abs_wi)\n","    return cond_prob\n","\n","#Find conditional probabilites based on test set for the (Word,Word) tuples\n","def find_cond_prob_absdisc(d, bi_dict, uni_dict, vocab, bi_test):\n","    cond_prob = dict()\n","    \n","    P_unif, lambdadot, N1_plus_wi1, N_bigrams, lambda_wi, P_abs_wi = get_params_absdisc(d, bi_dict, uni_dict, vocab)\n","    for k,v in bi_test.items():\n","        cond_prob[k] = get_P_abs_wi1_absdisc(k[1], k[0], d, uni_dict, bi_dict, N_bigrams, lambda_wi, P_abs_wi, lambdadot, P_unif)\n","    \n","    return cond_prob"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Ly4KJW16LTa","colab_type":"text"},"source":["###Find perplexity for the test corpus"]},{"cell_type":"code","metadata":{"id":"6R53fby-zhV9","colab_type":"code","colab":{}},"source":["#Find Perplexity\n","def find_perplexity(bgrams, cond_prob):\n","    tsum = 0\n","    s = sum(bgrams.values())\n","    for k,v in bgrams.items():\n","        rel_freq = v / s\n","        tsum -= rel_freq * math.log(cond_prob[k])  \n","    perplexity = math.exp(tsum)\n","    return perplexity"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2m8E3sU36PRz","colab_type":"text"},"source":["###Class based model processing"]},{"cell_type":"code","metadata":{"id":"lUrmICOeiGJe","colab_type":"code","colab":{}},"source":["pp_word_tags = []\n","POS_classes = [\"CD\",\"LS\", \"SENT\", \"SYM\", \"#\", \"$\", \"“\",\"\\\"\", \"''\", \"``\", \"“\", \"-LRB-\", \"-RRB-\", \",\", \":\", \".\",\"-NONE-\", \"”\"]\n","\n","for word, tag in ptb.tagged_words():\n","    if tag not in POS_classes:\n","        word = word.lower()\n","        pp_word_tags.append((word,tag))\n","\n","word_pos_dict = dict(pp_word_tags) #word:pos dict\n","word_pos_c = Counter(pp_word_tags) #(word,pos):count dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A6uGTa8AiGJo","colab_type":"code","colab":{}},"source":["#Note: Shuffling the data will give different perplexity results every time the code is run\n","np.random.shuffle(pp_word_tags)\n","l = int(4*len(pp_word_tags)/5)\n","\n","train_set = pp_word_tags[:l] \n","test_set = pp_word_tags[l:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4f7KR8qiGJw","colab_type":"code","colab":{}},"source":["words = [word for word,pos in train_set] #only words\n","pos = [pos for word,pos in train_set] #only tags\n","\n","uni_dict = Counter(words) #word:count dict\n","pos_uni = Counter(pos) #pos:count dict\n","pos_bi = Counter(zip(pos, islice(pos, 1, None))) #(pos,pos):count dict\n","\n","vocab = list(uni_dict.keys()) #all unique words\n","pos_classes = list(pos_uni.keys()) #all unique pos tags\n","\n","bi_test = find_bigrams(test_set) #(word,word) bigrams in test_set"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbrftlAViGKJ","colab_type":"code","colab":{}},"source":["#Find conditional probabilities\n","cp = find_cond_prob_class(0.9, uni_dict, word_pos_c, vocab, pos_uni, pos_bi, pos_classes, word_pos_dict, bi_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AYXOtKhMiGKO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593163270994,"user_tz":-120,"elapsed":3383,"user":{"displayName":"Awantee Deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQyP5l1inxcqIGxhx37HHAGXm1H1N-mYkv12YHVQ=s64","userId":"15044079699499406952"}},"outputId":"22c7d9e4-97c0-47ba-b343-be410df24dc6"},"source":["print(\"Perplexity of Class based model is\")\n","print(find_perplexity(bi_test, cp))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Perplexity of Class based model is\n","1010.6576210497838\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7ja078hW7BMI","colab_type":"text"},"source":["###Absolute Discounting model processing"]},{"cell_type":"code","metadata":{"id":"rFdC7JFiyG0q","colab_type":"code","colab":{}},"source":["train_words = words\n","uni_words = Counter(train_words)\n","bi_words = find_bigrams(train_set)\n","vocab_words = list(uni_words.keys())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7WXYiYD1lwc","colab_type":"code","colab":{}},"source":["#Find conditional probabilities\n","cp2 = find_cond_prob_absdisc(0.9, bi_words, uni_words, vocab_words, bi_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GbXQcQDU2tAF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593163315994,"user_tz":-120,"elapsed":48331,"user":{"displayName":"Awantee Deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQyP5l1inxcqIGxhx37HHAGXm1H1N-mYkv12YHVQ=s64","userId":"15044079699499406952"}},"outputId":"5c5e344b-b778-41ef-9825-74dbf0e42ee3"},"source":["print(\"Perplexity of Absolute Discounting based model is\")\n","print(find_perplexity(bi_test, cp2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Perplexity of Absolute Discounting based model is\n","1333.759847490673\n"],"name":"stdout"}]}]}