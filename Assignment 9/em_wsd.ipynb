{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"em_wsd.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"PE3l2i6u2psh","colab_type":"text"},"source":["## SNLP Summer 2020 Assignment 9\n","#### Expectation Maximization Algorithm for Word Sense Disambiguation\n","\n","\n","\n","Name: Awantee Deshpande\n","<br/>Id: 2581348\n","<br/>Email: s8awdesh@stud.uni-saarland.de\n","<br/>\n","<br/>Name: Lakshmi Rajendra Bashyam\n","<br/>Id: 2581455\n","<br/>Email: s8laraje@stud.uni-saarland.de"]},{"cell_type":"code","metadata":{"id":"Pd2EgDyC2psm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1594386789930,"user_tz":-120,"elapsed":2841,"user":{"displayName":"Awantee Deshpande","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQyP5l1inxcqIGxhx37HHAGXm1H1N-mYkv12YHVQ=s64","userId":"15044079699499406952"}},"outputId":"a84c3626-dba5-4a5f-df77-40fc286cac72"},"source":["import nltk\n","nltk.download('senseval')\n","from nltk.corpus import senseval\n","from collections import Counter\n","import time\n","import math\n","\n","import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package senseval to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/senseval.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DhR1TSOY2ps6","colab_type":"code","colab":{}},"source":["hard_f, interest_f, line_f, serve_f = senseval.fileids()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LvBFqTwt2ptE","colab_type":"text"},"source":["Class EM :\n","\n","EM_step: Does the expectation step\n","M_step: Does the maximisation step"]},{"cell_type":"code","metadata":{"id":"kmbYXUTd2ptF","colab_type":"code","colab":{}},"source":["class sample(object):\n","    def __init__(self, inst):\n","        self.label=inst.senses[0]\n","        p = inst.position\n","        context = [tuple[0]  for tuple in inst.context[p-5:p] if len(tuple)>1] \n","        #checking if list element is actually a tuple, phrasal elements are not\n","        context+= [tuple[0] for tuple in inst.context[p+1:p+6] if len(tuple)>1]\n","        self.context=context\n","\n","    def context_to_index(self, word_to_id):\n","        self.context=context_to_id(self.context, word_to_id)\n","        \n","class EM(object):\n","    def __init__(self, V, K):\n","        \"\"\"\n","        Randomly initializes the priors and the class conditional probabilitied\n","        :param samples: list of sample objects\n","        :set:    self.probs: vocabulary_size * num_senses sized matrix, i.e. each column is a class conditional probability distribution\n","                 self.priors: vector of prior probabilities\n","                \n","        \"\"\"\n","        self.V = V\n","        self.K = K\n","        \n","        #priors = P(Sk)\n","        priors=np.random.rand(K)\n","        #normalize\n","        priors=np.divide(priors, np.sum(priors))\n","        \n","        #probs = P(vj|sk)\n","        probs=np.random.rand(V, K)\n","        #normalize\n","        probs=np.divide(probs, np.sum(probs, axis=0))\n","\n","        self.priors=priors\n","        self.probs=probs\n","\n","    def E_step(self,samples):\n","        \"\"\"\"\n","        TO DO\n","        E-step\n","        :param samples: list of sample objects\n","        :return:  H is a matrix of size sample_size * num_senses\n","                H[i,k] = h_{i,k} from the slides\n","        \"\"\"\n","        probs = self.probs\n","        priors = self.priors\n","        H = np.zeros([len(samples),len(priors)])\n","        \n","        for i in range(len(samples)):\n","            context_index=samples[i].context #ci\n","            words_given_sense=probs[context_index, :] #P(vj|sk)\n","            context_given_sense=np.prod(words_given_sense, axis=0) #P(ci|sk)\n","            \n","            #multiply by priors\n","            context_probs=np.multiply(context_given_sense, priors)\n","            H[i,:] = np.divide(context_probs, np.sum(context_probs))\n","        \n","        return H\n","\n","    def M_step(self, H, C):\n","        \"\"\"\n","        TO DO\n","        M step \n","        Update self.priors and self.probs\n","        \"\"\"\n","        priors = self.priors\n","        probs = self.probs\n","        \n","        np.matmul(C.transpose(), H, out=probs)\n","        probs = np.divide(probs, np.sum(probs, axis=0))\n","        \n","        z_ = H.sum()\n","        priors = np.sum(H, axis=0)\n","        priors = np.divide(priors, z_)\n","        \n","        self.priors = priors\n","        self.probs = probs\n","\n","    def run(self, samples, C):\n","        \"\"\"\n","        Iterates E step and M step until convergence\n","        param: samples: list of sample objects\n","               C: num_samples x vocablary_size matrix where each row is contains the word counts in a given context\n","        return: labels: final clustering\n","    \n","        \"\"\"\n","        ll_graph = []\n","        \n","        MAX_ITER = 0\n","        #initial log likelihood\n","        ll = log_likelihood(samples, self.probs, self.priors)\n","        \n","        while True:\n","            #E-step        \n","            H = self.E_step(samples)\n","            #M-step\n","            self.M_step(H,C)          \n","\n","            old_ll = ll\n","            ll = log_likelihood(samples, self.probs, self.priors)\n","            ll_graph.append(ll)\n","            print(f\"Log likelihood = {ll}\")\n","            \n","            if abs(ll - old_ll) < 1e-5:\n","                break\n","            \n","            MAX_ITER += 1\n","            \n","        labels = np.argmax(H, axis=1)\n","        print(f\"Number of iterations = {MAX_ITER}\")\n","        return labels, ll_graph"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WCp8ZMwZ2ptL","colab_type":"text"},"source":["Other helper functions"]},{"cell_type":"code","metadata":{"id":"9VrLVu8P2ptN","colab_type":"code","colab":{}},"source":["def create_vocab(samples):\n","    words = set([w for s in samples for w in s.context])\n","    word_to_id = dict(zip(words, range(len(words))))\n","    senses = set([s.label for s in samples])\n","    return word_to_id, len(word_to_id), len(senses)\n","\n","\n","def context_to_id(context, word_to_id):\n","    return np.array([word_to_id[w] for w in context])\n","\n","\n","def log_likelihood(samples, probs, priors):\n","    \"\"\"\n","    :param samples: list of sample objects\n","    :param probs: vocab_size x num_senses sized matrix containing class conditional distributions\n","    :param priors: num_senses long vector with prior probs\n","    :return: log likelihood of corpus\n","    \"\"\"\n","    \n","    ll = 0\n","    for sample in samples:\n","        context_index = sample.context\n","        words_given_sense = probs[context_index, :]\n","        context_given_sense = np.prod(words_given_sense, axis=0)\n","        #multiply by priors\n","        context_probs = np.multiply(context_given_sense, priors)\n","        marginal = sum(context_probs)\n","        ll += np.log(marginal)\n","        \n","    return ll\n","\n","def counts_matrix(samples, V):\n","    \"\"\"\n","    :param samples: list of sample objects\n","    :param V: length of vocabulary\n","    :return: num_samples x vocablary_size matrix where each row is contains the word counts in a given context\n","    \"\"\"\n","    C = np.zeros([len(samples), V])\n","    it = 0\n","    total = 0\n","    \n","    for sample in samples:\n","        context_index = sample.context\n","        freq_dict = Counter(context_index) \n","        tuples = [tuple([x,y]) for x, y in freq_dict.items()]\n","        ids, counts = zip(*tuples)\n","\n","        C[it, ids] = counts\n","        it += 1\n","\n","    return C"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I-N3qbgH2ptS","colab_type":"text"},"source":["Main function"]},{"cell_type":"code","metadata":{"id":"X9MbjoHG2ptT","colab_type":"code","colab":{}},"source":["t0 = time.time()\n","instances = senseval.instances(hard_f)\n","\n","# all training samples as a list\n","samples = [sample(inst) for inst in instances]\n","\n","#V is size of Vocab, K is number of clusters\n","word_to_id, V, K = create_vocab(samples)\n","\n","#convert contexts to indices so they can be used for indexing\n","for smpl in samples:\n","    smpl.context_to_index(word_to_id)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pJR3xxnO2ptX","colab_type":"text"},"source":["Initialise EM object and run on the senseval \"hard\" samples"]},{"cell_type":"code","metadata":{"id":"8concwvj2ptY","colab_type":"code","colab":{},"outputId":"bf8825d6-527f-4b39-9d3d-4ded3124a6cd"},"source":["# initialize vj|s, priors\n","E_M = EM(V, K)  \n","\n","# C is a sample_size * vocab_size matrix\n","C = counts_matrix(samples, V)\n","\n","#run the model\n","labels, graph = E_M.run(samples,C)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Log likelihood = -205915.77165270355\n","Log likelihood = -204740.51491732986\n","Log likelihood = -204201.70211572605\n","Log likelihood = -203931.36900164175\n","Log likelihood = -203794.90872612534\n","Log likelihood = -203707.43851125106\n","Log likelihood = -203656.72406089984\n","Log likelihood = -203619.27640316306\n","Log likelihood = -203590.14765192024\n","Log likelihood = -203570.61998674803\n","Log likelihood = -203557.37129381456\n","Log likelihood = -203546.93096488854\n","Log likelihood = -203537.66176315185\n","Log likelihood = -203528.84950782693\n","Log likelihood = -203519.88068404232\n","Log likelihood = -203509.9205512534\n","Log likelihood = -203502.17771681427\n","Log likelihood = -203494.0962738753\n","Log likelihood = -203485.99255244355\n","Log likelihood = -203480.66951504897\n","Log likelihood = -203478.0275090736\n","Log likelihood = -203476.7290649542\n","Log likelihood = -203475.58151922232\n","Log likelihood = -203473.88332740968\n","Log likelihood = -203470.79074068373\n","Log likelihood = -203467.3090726516\n","Log likelihood = -203463.57083043444\n","Log likelihood = -203461.09056567732\n","Log likelihood = -203458.98977258438\n","Log likelihood = -203454.83848241036\n","Log likelihood = -203448.00350316675\n","Log likelihood = -203444.93572130078\n","Log likelihood = -203443.15847246215\n","Log likelihood = -203441.49776441732\n","Log likelihood = -203439.8077936336\n","Log likelihood = -203437.85124698197\n","Log likelihood = -203436.8985936705\n","Log likelihood = -203436.11590564615\n","Log likelihood = -203435.3371248393\n","Log likelihood = -203434.7866672446\n","Log likelihood = -203434.40076067124\n","Log likelihood = -203434.0772074285\n","Log likelihood = -203433.77207587395\n","Log likelihood = -203433.47064492374\n","Log likelihood = -203433.15011207905\n","Log likelihood = -203432.6915887848\n","Log likelihood = -203431.575863025\n","Log likelihood = -203428.7188602947\n","Log likelihood = -203426.35037378815\n","Log likelihood = -203425.9526363664\n","Log likelihood = -203425.77265154282\n","Log likelihood = -203425.4794595729\n","Log likelihood = -203425.0740998592\n","Log likelihood = -203424.7204640097\n","Log likelihood = -203424.32328146292\n","Log likelihood = -203423.73918059294\n","Log likelihood = -203423.19295163115\n","Log likelihood = -203422.78476743522\n","Log likelihood = -203422.4146347288\n","Log likelihood = -203422.0120953751\n","Log likelihood = -203421.4130011241\n","Log likelihood = -203419.51527831494\n","Log likelihood = -203417.9099291544\n","Log likelihood = -203417.80325229117\n","Log likelihood = -203417.75983571674\n","Log likelihood = -203417.69737429504\n","Log likelihood = -203417.58497389255\n","Log likelihood = -203417.36630849287\n","Log likelihood = -203416.95397275558\n","Log likelihood = -203416.3369071311\n","Log likelihood = -203415.73209303673\n","Log likelihood = -203415.1932173343\n","Log likelihood = -203414.1496430602\n","Log likelihood = -203412.63042699455\n","Log likelihood = -203411.42673655297\n","Log likelihood = -203410.7570598124\n","Log likelihood = -203410.5488709264\n","Log likelihood = -203410.41607290556\n","Log likelihood = -203410.22083023845\n","Log likelihood = -203409.79757090696\n","Log likelihood = -203409.08355890354\n","Log likelihood = -203408.54326640797\n","Log likelihood = -203408.30127142352\n","Log likelihood = -203408.0549908207\n","Log likelihood = -203407.48137227507\n","Log likelihood = -203406.43153463036\n","Log likelihood = -203405.77846756126\n","Log likelihood = -203405.371201178\n","Log likelihood = -203404.65341817826\n","Log likelihood = -203403.76794891007\n","Log likelihood = -203402.32740368953\n","Log likelihood = -203399.3585171937\n","Log likelihood = -203397.35709291106\n","Log likelihood = -203397.19662284155\n","Log likelihood = -203397.1529170981\n","Log likelihood = -203397.10834812306\n","Log likelihood = -203397.05655475333\n","Log likelihood = -203396.99964952364\n","Log likelihood = -203396.9437684338\n","Log likelihood = -203396.89593661812\n","Log likelihood = -203396.85999779362\n","Log likelihood = -203396.83539812185\n","Log likelihood = -203396.819180658\n","Log likelihood = -203396.80819770313\n","Log likelihood = -203396.7999575794\n","Log likelihood = -203396.79236735456\n","Log likelihood = -203396.7825362546\n","Log likelihood = -203396.7630478638\n","Log likelihood = -203396.70798192936\n","Log likelihood = -203396.51386209342\n","Log likelihood = -203395.81530661654\n","Log likelihood = -203394.55955866125\n","Log likelihood = -203393.9164709169\n","Log likelihood = -203393.51950158834\n","Log likelihood = -203393.33867878077\n","Log likelihood = -203393.31021474217\n","Log likelihood = -203393.29763783116\n","Log likelihood = -203393.28347807785\n","Log likelihood = -203393.26689995182\n","Log likelihood = -203393.2482772343\n","Log likelihood = -203393.22869011154\n","Log likelihood = -203393.209807959\n","Log likelihood = -203393.1933896685\n","Log likelihood = -203393.18056929574\n","Log likelihood = -203393.17135037328\n","Log likelihood = -203393.16137128687\n","Log likelihood = -203393.03131935705\n","Log likelihood = -203391.33232735808\n","Log likelihood = -203388.91624916426\n","Log likelihood = -203388.7369823229\n","Log likelihood = -203388.73189079604\n","Log likelihood = -203388.72792837504\n","Log likelihood = -203388.72324043463\n","Log likelihood = -203388.71730863943\n","Log likelihood = -203388.709432872\n","Log likelihood = -203388.69847308955\n","Log likelihood = -203388.68238107752\n","Log likelihood = -203388.6571071637\n","Log likelihood = -203388.61363975605\n","Log likelihood = -203388.52849229224\n","Log likelihood = -203388.32774445447\n","Log likelihood = -203387.78092789193\n","Log likelihood = -203386.78774371507\n","Log likelihood = -203386.189938405\n","Log likelihood = -203385.93495358288\n","Log likelihood = -203385.76706998725\n","Log likelihood = -203385.64345812253\n","Log likelihood = -203385.5499721791\n","Log likelihood = -203385.4797434633\n","Log likelihood = -203385.42825441287\n","Log likelihood = -203385.3915190869\n","Log likelihood = -203385.36577452725\n","Log likelihood = -203385.3477087669\n","Log likelihood = -203385.33465388318\n","Log likelihood = -203385.32458324177\n","Log likelihood = -203385.31596307975\n","Log likelihood = -203385.3075249912\n","Log likelihood = -203385.29794839572\n","Log likelihood = -203385.2852761285\n","Log likelihood = -203385.2653711196\n","Log likelihood = -203385.22645445808\n","Log likelihood = -203385.12442459547\n","Log likelihood = -203384.76041207978\n","Log likelihood = -203383.62867512347\n","Log likelihood = -203382.60008936492\n","Log likelihood = -203382.47996058973\n","Log likelihood = -203382.45410925295\n","Log likelihood = -203382.4289933575\n","Log likelihood = -203382.40132448717\n","Log likelihood = -203382.37130960886\n","Log likelihood = -203382.33920190035\n","Log likelihood = -203382.30439498945\n","Log likelihood = -203382.26464822286\n","Log likelihood = -203382.21557399517\n","Log likelihood = -203382.1512743328\n","Log likelihood = -203382.0682556324\n","Log likelihood = -203381.9734286991\n","Log likelihood = -203381.88656022362\n","Log likelihood = -203381.82516016168\n","Log likelihood = -203381.790270339\n","Log likelihood = -203381.77282138582\n","Log likelihood = -203381.7643715985\n","Log likelihood = -203381.76006955793\n","Log likelihood = -203381.7576125145\n","Log likelihood = -203381.75598809787\n","Log likelihood = -203381.75476170352\n","Log likelihood = -203381.75374548216\n","Log likelihood = -203381.75285491612\n","Log likelihood = -203381.75204792066\n","Log likelihood = -203381.75129880078\n","Log likelihood = -203381.75058665525\n","Log likelihood = -203381.74988958033\n","Log likelihood = -203381.74918096128\n","Log likelihood = -203381.74842607518\n","Log likelihood = -203381.74757794902\n","Log likelihood = -203381.7465716008\n","Log likelihood = -203381.74531554902\n","Log likelihood = -203381.743679051\n","Log likelihood = -203381.7414725411\n","Log likelihood = -203381.7384171531\n","Log likelihood = -203381.73409616938\n","Log likelihood = -203381.7278759999\n","Log likelihood = -203381.7187751916\n","Log likelihood = -203381.7052463775\n","Log likelihood = -203381.68482465306\n","Log likelihood = -203381.65362958313\n","Log likelihood = -203381.60595770922\n","Log likelihood = -203381.53510561818\n","Log likelihood = -203381.43819277125\n","Log likelihood = -203381.32582109753\n","Log likelihood = -203381.22397493062\n","Log likelihood = -203381.15380454613\n","Log likelihood = -203381.11279824632\n","Log likelihood = -203381.0601348182\n","Log likelihood = -203380.69810824352\n","Log likelihood = -203379.02725522494\n","Log likelihood = -203377.75066773375\n","Log likelihood = -203377.65751023873\n","Log likelihood = -203377.65311708182\n","Log likelihood = -203377.6511701051\n","Log likelihood = -203377.6493181782\n","Log likelihood = -203377.647189404\n","Log likelihood = -203377.64452269283\n","Log likelihood = -203377.6410136571\n"],"name":"stdout"},{"output_type":"stream","text":["Log likelihood = -203377.63623493575\n","Log likelihood = -203377.62954075265\n","Log likelihood = -203377.61991410854\n","Log likelihood = -203377.6057036216\n","Log likelihood = -203377.58417829406\n","Log likelihood = -203377.55087834355\n","Log likelihood = -203377.49918420095\n","Log likelihood = -203377.42221865687\n","Log likelihood = -203377.32147722968\n","Log likelihood = -203377.21771348646\n","Log likelihood = -203377.13684364935\n","Log likelihood = -203377.08082526925\n","Log likelihood = -203377.03586807247\n","Log likelihood = -203376.99128017033\n","Log likelihood = -203376.94108258453\n","Log likelihood = -203376.88156877938\n","Log likelihood = -203376.81129674753\n","Log likelihood = -203376.7325796382\n","Log likelihood = -203376.65176038668\n","Log likelihood = -203376.57622748913\n","Log likelihood = -203376.51066419674\n","Log likelihood = -203376.45616764494\n","Log likelihood = -203376.41112105318\n","Log likelihood = -203376.3715837037\n","Log likelihood = -203376.33102646624\n","Log likelihood = -203376.279173021\n","Log likelihood = -203376.19957875588\n","Log likelihood = -203376.07071656216\n","Log likelihood = -203375.88940182977\n","Log likelihood = -203375.7093023814\n","Log likelihood = -203375.59210168483\n","Log likelihood = -203375.531301125\n","Log likelihood = -203375.4944563766\n","Log likelihood = -203375.46342752842\n","Log likelihood = -203375.43208961637\n","Log likelihood = -203375.39933083713\n","Log likelihood = -203375.36601037884\n","Log likelihood = -203375.33380441595\n","Log likelihood = -203375.3045250131\n","Log likelihood = -203375.27956258605\n","Log likelihood = -203375.25954848927\n","Log likelihood = -203375.24434550776\n","Log likelihood = -203375.2332919126\n","Log likelihood = -203375.22551257187\n","Log likelihood = -203375.22015370434\n","Log likelihood = -203375.2165014138\n","Log likelihood = -203375.21401118828\n","Log likelihood = -203375.2122904741\n","Log likelihood = -203375.21106518377\n","Log likelihood = -203375.2101461451\n","Log likelihood = -203375.20940135288\n","Log likelihood = -203375.20873482377\n","Log likelihood = -203375.20807081484\n","Log likelihood = -203375.20734172795\n","Log likelihood = -203375.20647809323\n","Log likelihood = -203375.20539923094\n","Log likelihood = -203375.20400339292\n","Log likelihood = -203375.202156281\n","Log likelihood = -203375.19967699944\n","Log likelihood = -203375.19632067037\n","Log likelihood = -203375.1917575836\n","Log likelihood = -203375.18555004566\n","Log likelihood = -203375.1771310652\n","Log likelihood = -203375.165794467\n","Log likelihood = -203375.15071534607\n","Log likelihood = -203375.1310324366\n","Log likelihood = -203375.10603423152\n","Log likelihood = -203375.0754794369\n","Log likelihood = -203375.04001391862\n","Log likelihood = -203375.00149604454\n","Log likelihood = -203374.9628898669\n","Log likelihood = -203374.9274852882\n","Log likelihood = -203374.8977274153\n","Log likelihood = -203374.87444597817\n","Log likelihood = -203374.85701563576\n","Log likelihood = -203374.84413870698\n","Log likelihood = -203374.83455760134\n","Log likelihood = -203374.82735220852\n","Log likelihood = -203374.8219193273\n","Log likelihood = -203374.8178523975\n","Log likelihood = -203374.81484750877\n","Log likelihood = -203374.8126588485\n","Log likelihood = -203374.81108443873\n","Log likelihood = -203374.80996209508\n","Log likelihood = -203374.80916596742\n","Log likelihood = -203374.808601467\n","Log likelihood = -203374.80819928335\n","Log likelihood = -203374.80790955795\n","Log likelihood = -203374.80769685825\n","Log likelihood = -203374.80753612684\n","Log likelihood = -203374.80740953356\n","Log likelihood = -203374.80730396076\n","Log likelihood = -203374.80720870144\n","Log likelihood = -203374.8071126134\n","Log likelihood = -203374.80699917141\n","Log likelihood = -203374.8068358076\n","Log likelihood = -203374.8065489552\n","Log likelihood = -203374.80596405367\n","Log likelihood = -203374.80466032267\n","Log likelihood = -203374.8016192112\n","Log likelihood = -203374.7943784697\n","Log likelihood = -203374.77703407008\n","Log likelihood = -203374.73580949465\n","Log likelihood = -203374.64158184506\n","Log likelihood = -203374.45390239684\n","Log likelihood = -203374.2008114588\n","Log likelihood = -203374.0420040742\n","Log likelihood = -203374.0034471253\n","Log likelihood = -203373.997982587\n","Log likelihood = -203373.99671452626\n","Log likelihood = -203373.99592878605\n","Log likelihood = -203373.9951513733\n","Log likelihood = -203373.99425986988\n","Log likelihood = -203373.99317768493\n","Log likelihood = -203373.99182051216\n","Log likelihood = -203373.99006973408\n","Log likelihood = -203373.98773902247\n","Log likelihood = -203373.9845131428\n","Log likelihood = -203373.9798188436\n","Log likelihood = -203373.97252518724\n","Log likelihood = -203373.9601764419\n","Log likelihood = -203373.93680569995\n","Log likelihood = -203373.88603611733\n","Log likelihood = -203373.7590272342\n","Log likelihood = -203373.4339705783\n","Log likelihood = -203372.88083850243\n","Log likelihood = -203372.55852062732\n","Log likelihood = -203372.51926003213\n","Log likelihood = -203372.51179039272\n","Log likelihood = -203372.5039243486\n","Log likelihood = -203372.4956096749\n","Log likelihood = -203372.48719081946\n","Log likelihood = -203372.47909961257\n","Log likelihood = -203372.4717547649\n","Log likelihood = -203372.46544981425\n","Log likelihood = -203372.4602756305\n","Log likelihood = -203372.4561116164\n","Log likelihood = -203372.45267651274\n","Log likelihood = -203372.4495948371\n","Log likelihood = -203372.44643294124\n","Log likelihood = -203372.4426755923\n","Log likelihood = -203372.43761926005\n","Log likelihood = -203372.4301273772\n","Log likelihood = -203372.4180952036\n","Log likelihood = -203372.3972356727\n","Log likelihood = -203372.3583391668\n","Log likelihood = -203372.2822583522\n","Log likelihood = -203372.13957719906\n","Log likelihood = -203371.92999163555\n","Log likelihood = -203371.74326595193\n","Log likelihood = -203371.65165188696\n","Log likelihood = -203371.62227073155\n","Log likelihood = -203371.61420695737\n","Log likelihood = -203371.6118808068\n","Log likelihood = -203371.61105387844\n","Log likelihood = -203371.6106613264\n","Log likelihood = -203371.61042721354\n","Log likelihood = -203371.61026984747\n","Log likelihood = -203371.6101582047\n","Log likelihood = -203371.6100767055\n","Log likelihood = -203371.61001590628\n","Log likelihood = -203371.60996957155\n","Log likelihood = -203371.60993344596\n","Log likelihood = -203371.60990460028\n","Log likelihood = -203371.60988100036\n","Log likelihood = -203371.6098612373\n","Log likelihood = -203371.60984432203\n","Log likelihood = -203371.60982956638\n","Log likelihood = -203371.60981648113\n","Log likelihood = -203371.60980471637\n","Log likelihood = -203371.60979402225\n","Log likelihood = -203371.60978421307\n","Number of iterations = 395\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MyBug4dp2ptc","colab_type":"text"},"source":["### Analysis"]},{"cell_type":"markdown","metadata":{"id":"Uuh-iqSL2ptd","colab_type":"text"},"source":["1) \n","Some kinds of data result from drawing from multiple distributions. If the parameters of those distributions are known, it is simple to determine which distribution a data point comes from. But if those parameters are not known, expectation maximization can be used to determine the likelihood of a data point belonging to a particular distribution using some latent variable.\n","EM is particularly used to fit a model in an unsupervised setting. It estimates the values of the latent variables, optimises the model, and then repeats these steps till the log likelihood converges.\n","<br/>One well known use-case of Expectation Maximization is in the Baum-Welch algorithm for Hidden Markov Models. It is used to calculate the state transition probabilities and the emission probabilities to maximise the given data observation."]},{"cell_type":"markdown","metadata":{"id":"-aT93YKU2ptd","colab_type":"text"},"source":["2)\n","The code for the expectation and maximisations steps is in the functions E_step and M_step respectively in this notebook.\n","The change in log likelihood is modeled below as follows:\n","(It can be observed that the log likelihood increases over the iterations until it converges)"]},{"cell_type":"code","metadata":{"id":"zdThXzOY2pte","colab_type":"code","colab":{},"outputId":"7e9772af-96de-4f4f-db72-463342a2c29c"},"source":["plt.plot(graph, list(range(1, len(graph)+1)))\n","plt.xlabel(\"Log likelihood\")\n","plt.ylabel(\"No. of iterations\")\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"o5PHiaFZ2pth","colab_type":"text"},"source":["3) \n","The outputted ordered frequency of labels within each cluster is displayed by the code below:\n","We can see that all the senses are assigned to different clusters with varying frequencies by the EM algorithm.\n","\n","In the code snippet below, we try to estimate the true clustering of the samples by using the labels known to us (these cannot be used for unsupervised training), and we should expect a clear majority of one kind of sense in one cluster. But this does not happen. The sense 'HARD1' has a large set of examples as compared to 'HARD2' and 'HARD3'. Because of the random initialisation and imbalanced cluster sizes, EM does not give an exact split according to the senses."]},{"cell_type":"code","metadata":{"id":"HeY3j17z2pti","colab_type":"code","colab":{},"outputId":"905efb37-1b21-4051-d0f3-1f903e70eafe"},"source":["clusters = [[] for i in range(K)]\n","for i in range(len(samples)):\n","    cl_i = labels[i]\n","    clusters[cl_i].append(samples[i])\n","\n","i = 0\n","for cluster in clusters:\n","    sense_counts = Counter([sample.label for sample in cluster])\n","    ordered = sense_counts.most_common()\n","    print(\"ordered list of senses within cluster {0}: \".format(i),ordered)\n","    i += 1\n","\n","t1 = time.time()\n","total_time = t1-t0\n","print(\"Time: \", total_time)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ordered list of senses within cluster 0:  [('HARD1', 1357), ('HARD3', 174), ('HARD2', 120)]\n","ordered list of senses within cluster 1:  [('HARD1', 449), ('HARD2', 210), ('HARD3', 67)]\n","ordered list of senses within cluster 2:  [('HARD1', 1649), ('HARD2', 172), ('HARD3', 135)]\n","Time:  138.99180507659912\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"efYmkGK72ptm","colab_type":"code","colab":{},"outputId":"b594e10e-9330-43a3-ad77-0b7349515ac7"},"source":["clusters2 = [[] for i in range(K)]\n","labels2 = {'HARD1':0, 'HARD2':1, 'HARD3':2}\n","\n","for i in range(len(samples)):\n","    cl_i = labels2[samples[i].label]\n","    clusters2[cl_i].append(samples[i])\n","\n","i = 0\n","for cluster in clusters2:\n","    sense_counts = Counter([sample.label for sample in cluster])\n","    ordered = sense_counts.most_common()\n","    print(\"ordered list of senses within cluster {0}: \".format(i),ordered)\n","    i += 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ordered list of senses within cluster 0:  [('HARD1', 3455)]\n","ordered list of senses within cluster 1:  [('HARD2', 502)]\n","ordered list of senses within cluster 2:  [('HARD3', 376)]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m8GNBd_B2ptq","colab_type":"text"},"source":["4)\n","EM does not find the global optimum. Similar to gradient descent, it only converges to a point where the log likelihood ~ 0 w.r.t the parameters. This kind of search is local and and largely dependent on the first initialisations of the parameters. \n","\n","As a result of this, EM can also be slow to converge based on how it is initialised."]},{"cell_type":"markdown","metadata":{"id":"PHx8TtzD2ptr","colab_type":"text"},"source":["#### ----------------------------------------------------------------------------------xxxxxx-----------------------------------------------------------------------------------------------------"]}]}